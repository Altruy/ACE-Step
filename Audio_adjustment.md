Excellent â€” hereâ€™s a new companion document specifically focused on understanding and controlling audio generation behavior in your ACE-Step API using the /generate endpoint parameters.

This guide explains how every key parameter affects music quality, style, coherence, emotion, and diversity â€” so you can precisely tune the output.

â¸»

ğŸ“˜ Download link:
ğŸ‘‰ Download ACE_STEP_AUDIO_CONTROL_GUIDE.mdï¿¼

â¸»

ğŸ›ï¸ ACE-Step Audio Generation Control Guide

(Fine-tuning output quality, emotion, and style using /generate parameters)

This guide is designed to help you master control over how ACE-Step produces music â€” balancing creativity, coherence, and fidelity â€” by manipulating the FastAPI parameters in the /generate endpoint.

â¸»

ğŸ§  1ï¸âƒ£ Core Generation Overview

ACE-Step uses text-to-music diffusion â€” transforming textual and lyrical input into waveforms through iterative refinement.
Each parameter in /generate adjusts one part of that diffusion and conditioning process.

Think of it as:
	â€¢	ğŸ¤ Prompt â†’ Defines the musical identity
	â€¢	ğŸ“ Lyrics â†’ Structures rhythm, tone, emotion
	â€¢	âš™ï¸ Guidance â†’ Controls fidelity vs creativity
	â€¢	ğŸ§® Steps + Seeds â†’ Affect consistency and detail
	â€¢	ğŸ§  ERG / OSS â†’ Manage variation and stability

â¸»

ğŸšï¸ 2ï¸âƒ£ Master Parameters Breakdown

ğŸ¶ Audio Duration (audio_duration)
	â€¢	Controls: Total length (seconds)
	â€¢	Effect: Longer durations = more musical structure but higher VRAM use
	â€¢	Recommended ranges:
	â€¢	30â€“60 â†’ short clips
	â€¢	90â€“120 â†’ full songs
	â€¢	Tip: A5000 GPUs handle up to ~90s comfortably

â¸»

ğŸ§¾ Prompt (prompt)
	â€¢	Controls: Global style, mood, instrumentation, and tempo
	â€¢	Examples:
	â€¢	"lofi chill beat, rainy night, warm piano, deep bass"
	â€¢	"epic orchestral, cinematic tension, strings and brass"
	â€¢	"k-pop, upbeat, dance, electronic synth"

Prompt writing tips:
	â€¢	Use comma-separated tags (acts like â€œembedding hintsâ€).
	â€¢	Avoid full sentences.
	â€¢	Place mood or genre keywords first.
	â€¢	Add up to 10 descriptors.

â¸»

ğŸ¤ Lyrics (lyrics)
	â€¢	Controls: Phonetic structure, rhythm, emotional tone
	â€¢	Supports [intro], [verse], [chorus], [bridge], [outro]
	â€¢	Multilingual â€” English, Chinese, Korean, Japanese, Spanish, etc.
	â€¢	Tip: Keep ~8â€“12 syllables per line for rhythmic coherence.

â¸»

âš™ï¸ 3ï¸âƒ£ Diffusion and Guidance Parameters

ğŸª„ Inference Steps (infer_step)
	â€¢	Controls: How many diffusion refinements are applied
	â€¢	Range: 20â€“120
	â€¢	Effect:
	â€¢	Higher = more coherent & detailed
	â€¢	Lower = faster, sometimes noisier
	â€¢	Recommended: 50â€“70 for A5000

â¸»

ğŸšï¸ Guidance Scale (guidance_scale)
	â€¢	Controls: Strength of prompt & lyric adherence
	â€¢	Range: 1â€“25
	â€¢	Effect:
	â€¢	Low (5â€“10): loose, creative, more noise
	â€¢	Medium (12â€“17): balanced clarity
	â€¢	High (18â€“25): strict fidelity, robotic if too high
	â€¢	Recommended: 15.0

â¸»

âš™ï¸ CFG Type (cfg_type)
	â€¢	Options: "apg", "cfg", "cfg_star"
	â€¢	Effects:
	â€¢	"apg" â€” Adaptive guidance (balanced realism & creativity) âœ… Recommended
	â€¢	"cfg" â€” Classic classifier-free guidance (strong adherence)
	â€¢	"cfg_star" â€” Advanced guidance for stable instrumentals

â¸»

ğŸ”„ Scheduler Type (scheduler_type)
	â€¢	Options: "euler", "heun", "pingpong"
	â€¢	Effects:
	â€¢	"euler" â€” Fast, clean diffusion âœ… Recommended default
	â€¢	"heun" â€” Smoother audio, slower
	â€¢	"pingpong" â€” Dynamic variation, creative artifacts

â¸»

ğŸŒŠ Omega Scale (omega_scale)
	â€¢	Controls: Balance of smoothness vs expressiveness
	â€¢	Typical: 8â€“12
	â€¢	Higher values: more dynamic range and contrast
	â€¢	Lower values: smoother, but flatter sound

â¸»

ğŸ§® 4ï¸âƒ£ Seed and Sampling Controls

ğŸ² Seeds (actual_seeds)
	â€¢	Controls: Random noise initialization for deterministic output
	â€¢	Example: [135767468]
	â€¢	Use cases:
	â€¢	Same seed = reproducible track
	â€¢	Multiple seeds = batch variations
	â€¢	Tip: Change seed to explore creative variants of same lyrics/prompt.

â¸»

ğŸ§­ OSS Steps (oss_steps)
	â€¢	Controls: Which diffusion steps are used explicitly
	â€¢	Default: [] (all steps)
	â€¢	Example: [1, 5, 10, 20, 30, 40, 50, 60]
	â€¢	Useful for partial generation or debug control.
	â€¢	Advanced users can use this to shorten inference time.

â¸»

ğŸ§  5ï¸âƒ£ ERG (Entropy Rectifying Guidance)

ERG adds controlled stochasticity into text/lyric embeddings, encouraging diversity and emotion.

Parameter	Meaning	Effect
use_erg_tag	Randomizes prompt embeddings	More diverse genre texture
use_erg_lyric	Randomizes lyric embeddings	More expressive phrasing
use_erg_diffusion	Adds variety in denoising	Less repetitive loops

ğŸ’¡ Recommended settings:
All three set to true for organic, expressive generation.
Set to false for precise reproductions or benchmarking.

â¸»

ğŸŒ€ 6ï¸âƒ£ Advanced Guidance Dynamics

guidance_interval
	â€¢	Fraction of steps where guidance is active (0.0â€“1.0)
	â€¢	Example: 0.5 â†’ guidance used during 50% of diffusion
	â€¢	Higher values: more faithful to prompt
	â€¢	Lower values: freer improvisation

â¸»

guidance_interval_decay
	â€¢	How fast guidance weakens during diffusion
	â€¢	Range: 0.0â€“1.0
	â€¢	0.0: Constant adherence
	â€¢	0.5+: Gradual shift to creativity
	â€¢	Combine with min_guidance_scale for controlled fade-outs.

â¸»

min_guidance_scale
	â€¢	Minimum guidance strength after decay
	â€¢	Range: 0â€“10
	â€¢	Example: min_guidance_scale: 3.0 keeps it semi-grounded

â¸»

ğŸ›ï¸ Double Condition Guidance

Allows separate control for tags and lyrics.

Parameter	Role	Recommended
guidance_scale_text	Extra scale for tag embeddings	0.0 (disabled) or >1.0 for double guidance
guidance_scale_lyric	Extra scale for lyric embeddings	Use if lyrics dominate over style


â¸»

ğŸ§ 7ï¸âƒ£ Precision and Performance

Parameter	Default	Effect
bf16	true	Uses bfloat16 for faster inference (safe for A5000)
torch_compile	false	Compiles model for speed, requires Triton (enable if stable)
device_id	0	GPU index


â¸»

ğŸ—‚ï¸ 8ï¸âƒ£ Output Control

Parameter	Description	Example
output_path	Destination path for saved file	/workspace/ace-step-api/generated/song.wav
Format	Default is .wav	Conversion to .mp3 supported manually
Multiple outputs	Use different seeds or filenames	Creates separate files per run


â¸»

ğŸ”¬ 9ï¸âƒ£ Recommended Parameter Recipes

ğŸµ Balanced Realism (Default)

{
  "infer_step": 60,
  "guidance_scale": 15.0,
  "cfg_type": "apg",
  "scheduler_type": "euler",
  "omega_scale": 10.0,
  "use_erg_tag": true,
  "use_erg_lyric": true,
  "use_erg_diffusion": true
}

Produces emotionally rich, rhythmic, and coherent tracks.

â¸»

ğŸ¶ Experimental / Freestyle

{
  "guidance_scale": 9.0,
  "guidance_interval": 0.3,
  "guidance_interval_decay": 0.5,
  "min_guidance_scale": 2.0,
  "use_erg_tag": true,
  "use_erg_lyric": true,
  "use_erg_diffusion": true
}

Looser adherence, more creativity, ideal for â€œjam sessionâ€ vibes.

â¸»

ğŸ§ High Fidelity / Precise

{
  "guidance_scale": 18.0,
  "cfg_type": "cfg_star",
  "use_erg_tag": false,
  "use_erg_lyric": false,
  "use_erg_diffusion": false
}

Tight synchronization to prompt/lyrics â€” best for structured songs or covers.

â¸»

ğŸ“Š 10ï¸âƒ£ Optimization for RTX A5000

Setting	Recommended	Notes
bf16: true	âœ… Faster inference	
audio_duration: â‰¤ 90	âœ… Prevents OOM	
infer_step: 50â€“60	âœ… Balance of speed/detail	
use_erg_diffusion: true	âœ… Adds richness without extra memory	
torch_compile: false	âš ï¸ Optional, only if stable	


â¸»

ğŸ’¡ 11ï¸âƒ£ Practical Tips
	â€¢	Keep audio_duration and infer_step proportional (longer â†’ more steps).
	â€¢	Use same seed to compare parameter differences.
	â€¢	Lower guidance_scale = freer sound.
	â€¢	Raise omega_scale = more punchy transient detail.
	â€¢	Use ERG on when exploring new genres or moods.
	â€¢	Save your successful parameter sets in JSON for reuse.

â¸»

âœ… 12ï¸âƒ£ Summary

Category	What It Controls
ğŸ¶ prompt, lyrics	Core musical content
âš™ï¸ infer_step, guidance_scale, cfg_type	Diffusion accuracy
ğŸ§  use_erg_*, guidance_interval_*	Expression and variation
ğŸ§® actual_seeds, oss_steps	Reproducibility and sampling
ğŸ’¾ output_path	Save location
ğŸ§ bf16, torch_compile	Performance and precision


â¸»

ğŸµ With this guide, you can now precisely craft musical emotion, structure, and diversity â€” directly from your FastAPI endpoint.

Would you like me to also generate a â€œparameter preset libraryâ€ JSON file (e.g., presets.json) that you can load dynamically in your app to switch between Balanced, Freestyle, and Precision modes?